{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n",
    "\n",
    "Your task is to find parameters $\\beta$ of a linear model that approximates the following observations. Each observation is decribed by only one input feature $x_{1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data for the file\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Display the first 5 rows of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a matrix of the input feature of the observations\n",
    "x1 = data[['x1']].values\n",
    "\n",
    "# Get a vector of target values you need to approximate\n",
    "y = data['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the observations\n",
    "\n",
    "plt.figure(figsize=(9, 4.5))\n",
    "plt.scatter(x1, y, linewidth=3, label=\"Observations\")\n",
    "plt.xlabel(r'$x_{1}$', size=14)\n",
    "plt.xticks(size=14)\n",
    "plt.ylabel(r\"y\", size=14)\n",
    "plt.yticks(size=14)\n",
    "plt.legend(loc='best', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create matrix X\n",
    "\n",
    "Now you have the vector of targets $y = (y_{1}, y_{2}, ..., y_{n})^{T}$. Create a matrix $X$ that is defined as\n",
    "\n",
    "$$\n",
    "X = \\left( \\begin{array}{ccccc} \n",
    "         1 & x_{11} & x_{12} & \\cdots & x_{1d} \\\\ \n",
    "         1 & x_{21} & x_{22} & \\cdots & x_{2d} \\\\ \n",
    "         \\vdots & \\vdots  & \\vdots  & \\cdots & \\vdots  \\\\\n",
    "         1 & x_{n1} & x_{n2} & \\cdots & x_{nd} \\\\ \n",
    "         \\end{array} \\right)\n",
    "$$\n",
    "\n",
    "Rememder that your observations have only one input feature $x_{i1}$.\n",
    "\n",
    "**Hint:** Use `np.ones()` function to generate a vector of ones $(1, 1, ..., 1)^{T}$. To concatenate two matrices $a$ and $b$ use function `np.hstack((a, b))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ... # Put your code here (2 lines)\n",
    "\n",
    "print(\"Output:\")\n",
    "X[:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected otput :  \n",
    "`[[ 1.   , -1.   ], \n",
    "  [ 1.   , -0.959]]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.array([0, 0])\n",
    "\n",
    "print(\"Output:\")\n",
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss\n",
    "\n",
    "Calculate the loss function defined as:\n",
    "\n",
    "$$\n",
    "L(\\beta) = \\frac{1}{n} (X\\beta - y)^{T}(X\\beta - y)\n",
    "$$\n",
    "\n",
    "**Hint:** To multiply two matrices $a$ and $b$ use functions `a.dot(b)` or `np.dot(a, b)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(beta):\n",
    "    loss = ... # Put your code here (1 line)\n",
    "    return loss\n",
    "\n",
    "loss = loss_func(beta)\n",
    "\n",
    "print(\"Output:\")\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected otput :  \n",
    "`2.19695098`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient of the loss function\n",
    "\n",
    "Calculate gradient of the loss function $\\nabla L$ defined as:\n",
    "    \n",
    "$$\n",
    "\\nabla L = \\frac{\\partial L}{\\partial \\beta} = \\frac{2}{n} X^{T} (X\\beta - y)\n",
    "$$\n",
    "\n",
    "**Hint:** To multiply two matrices $a$ and $b$ use functions `a.dot(b)` or `np.dot(a, b)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_func(beta):\n",
    "    grad = ... # Put your code here (1 line)\n",
    "    return grad\n",
    "\n",
    "grad = grad_func(beta)\n",
    "\n",
    "print(\"Output:\")\n",
    "grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected otput :  \n",
    "`[-1.40972   , -1.52095704]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "\n",
    "Now implement gradient descent for the approximation. The update rule for $\\beta$ is:\n",
    "\n",
    "$$\n",
    "\\beta_{(t+1)} = \\beta_{(t)} - \\alpha \\nabla L(\\beta_{(t)})\n",
    "$$\n",
    "\n",
    "Estimate how many iterations $t$ it is needed to satisfy the following stop criterion:\n",
    "\n",
    "$$\n",
    "| L(\\beta_{(t)} - L(\\beta_{(t-1)} | < 10^{-4}\n",
    "$$\n",
    "\n",
    "**Hint:** To multiply two matrices $a$ and $b$ use functions `a.dot(b)` or `np.dot(a, b)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1              # learning rate\n",
    "beta = np.array([0, 0])  # init beta, again :)\n",
    "\n",
    "beta_collector = [beta]\n",
    "loss_collector = [loss_func(beta)]\n",
    "\n",
    "for i_iter in range(1000): # for each iteration\n",
    "    \n",
    "    # Calculate gradient\n",
    "    grad = ... # Put your code here (1 line)\n",
    "    \n",
    "    # Update beta\n",
    "    beta = ... # Put your code here (1 line)\n",
    "    \n",
    "    # Save new beta\n",
    "    beta_collector.append(beta)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = ... # Put your code here (1 line)\n",
    "    \n",
    "    # Save loss\n",
    "    loss_collector.append(loss)\n",
    "    \n",
    "    # Stop criterion\n",
    "    if np.abs( loss_collector[-1] - loss_collector[-2] ) < 10**-4:\n",
    "        print(\"Iteration: \", i_iter)\n",
    "        print(\"Beta: \", beta)\n",
    "        print(\"Loss: \", loss)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "plt.figure(figsize=(9, 4.5))\n",
    "plt.plot(loss_collector, linewidth=3, label=\"GD\", color='C3')\n",
    "plt.xlabel(r'Iteration number', size=14)\n",
    "plt.xticks(size=14)\n",
    "plt.ylabel(r\"Loss function value\", size=14)\n",
    "plt.yticks(size=14)\n",
    "plt.legend(loc='best', fontsize=14, ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
